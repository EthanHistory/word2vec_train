{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy issue with gensim\n",
    "# https://stackoverflow.com/questions/78279136/importerror-cannot-import-name-triu-from-scipy-linalg-gensim\n",
    "\n",
    "!pip install scipy==1.10.1 numpy gensim scikit-learn matplotlib spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load job description data\n",
    "df = pd.read_csv(\"jobspy.csv\")\n",
    "valid_descriptions = df[~df['description'].isna()]['description']\n",
    "\n",
    "# Tokenize job descriptions by spacy\n",
    "tokenized_descriptions = []\n",
    "for description in tqdm(valid_descriptions):\n",
    "    tokens = nlp(description)\n",
    "    tokenized_descriptions.append([token.text for token in tokens if not token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (or use a preprocessed one)\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(tokenized_descriptions, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.train(tokenized_descriptions, total_examples=len(tokenized_descriptions), epochs=10)\n",
    "\n",
    "# Get word embeddings\n",
    "word_embeddings = model.wv\n",
    "\n",
    "# Example of accessing word embeddings\n",
    "print(\"Embedding for 'example':\", word_embeddings['example'])\n",
    "\n",
    "# Visualize word embeddings using t-SNE\n",
    "def tsne_plot(model):\n",
    "    labels = []\n",
    "    wordvecs = []\n",
    "\n",
    "    for word in model.wv.key_to_index:\n",
    "        wordvecs.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    tsne_model = TSNE(perplexity=2, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(np.array(wordvecs))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        plt.annotate(labels[i], xy=(x[i], y[i]), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "# Plot t-SNE visualization\n",
    "tsne_plot(model)\n",
    "\n",
    "# Example application: similarity between words\n",
    "similarity = model.wv.similarity('example', 'sentence')\n",
    "print(\"Similarity between 'word1' and 'word2':\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
